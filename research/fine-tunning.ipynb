{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all importtant libraries\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma  # Chroma vector store\n",
    "from langchain.vectorstores import FAISS  # FAISS vector store for fast local search\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import CTransformers\n",
    "#from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "#import faiss\n",
    "#from transformers import pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Final _proj\\\\medical chatbot\\\\Chatbot original\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_pdf(data):      #Load the pdf from data floder\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)  #Load only pdf file\n",
    "    documents = loader.load() \n",
    "    return documents\n",
    "\n",
    "documents = load_pdf(data=\"data/\")\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text chunk: 1879\n"
     ]
    }
   ],
   "source": [
    "def text_split(extracted_data): \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)  # Larger chunks for fewer docs\n",
    "    text_chunks = text_splitter.split_documents(extracted_data) \n",
    "    return text_chunks \n",
    "\n",
    "text_chunk = text_split(documents)      #Split the data imto small chunks\n",
    "print(\"Length of Text chunk:\", len(text_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rohit\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Questions and Answers:\n",
      "Question: What is diabetes?\n",
      "Answer: a condition that happens when your blood sugar (glucose) is too high\n",
      "\n",
      "Question: What are the three most common forms of diabetes?\n",
      "Answer: Type 2 diabetes is the most common form, representing 90% to 95% of all diabetes cases\n",
      "\n",
      "Question: What is the most common type of diabetes?\n",
      "Answer: Type 1 diabetes. These symptoms are usually more intense in Type 1 diabetes than Type 2 diabetes.\n",
      "\n",
      "Question: What is the most common cause of diabetes?\n",
      "Answer: Insulin resistance. Type 2 diabetes mainly results from insulin resistance. Several factors and conditions contribute to varying degrees of insulin resistance, including obesity, lack of physical activity, diet, hormonal imbalances, genetics and certain medications.\n",
      "\n",
      "Question: What is the most common type of cardiovascular disease?\n",
      "Answer: Coronary artery disease. br>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the Hugging Face model for text-to-text generation (consider using a better model if available)\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# Define the prompt template for generating questions based on context and answer\n",
    "QUESTION_PROMPT_TEMPLATE = (\n",
    "    \"Based on the following context and answer, generate a clear and meaningful question:\\n\\n\"\n",
    "    \"Context: {content}\\n\"\n",
    "    \"Answer: {answer}\\n\\n\"\n",
    "    \"Question:\"\n",
    ")\n",
    "\n",
    "# Define the prompt template for generating answers based on context and question\n",
    "ANSWER_PROMPT_TEMPLATE = (\n",
    "    \"Using the following context, provide a concise, informative, and understandable answer to the question:\\n\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Context: {content}\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "# List to store the generated question-answer pairs\n",
    "qa_pairs = []\n",
    "\n",
    "# Iterate through the documents and generate questions and answers\n",
    "for doc in documents[:5]:\n",
    "    content = doc.page_content\n",
    "\n",
    "    # Extracting a meaningful answer from content\n",
    "    if \"is\" in content:\n",
    "        answer = content.split(\"is\")[-1].strip().rstrip(\".\")\n",
    "    else:\n",
    "        answer = \"Unknown\"\n",
    "\n",
    "    # Create prompt for generating a question based on the context and answer\n",
    "    question_prompt = QUESTION_PROMPT_TEMPLATE.format(content=content, answer=answer)\n",
    "    \n",
    "    # Generate question using the Hugging Face model (Flan-T5)\n",
    "    question_response = qa_pipeline(question_prompt, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "    \n",
    "    # Clean up response to ensure it is a valid question\n",
    "    question = question_response.strip()\n",
    "    \n",
    "    # Create prompt for generating an answer based on the context and generated question\n",
    "    answer_prompt = ANSWER_PROMPT_TEMPLATE.format(question=question, content=content)\n",
    "    \n",
    "    # Generate answer using the Hugging Face model (Flan-T5)\n",
    "    # Set max_length to allow longer answers and min_length to enforce minimum length\n",
    "    answer_response = qa_pipeline(answer_prompt, max_length=50, min_length=10, num_return_sequences=1)[0]['generated_text']\n",
    "    \n",
    "    # Clean up response to ensure it is a valid answer\n",
    "    generated_answer = answer_response.strip()\n",
    "\n",
    "    # Append the results to qa_pairs\n",
    "    qa_pairs.append({\"question\": question, \"answer\": generated_answer})\n",
    "\n",
    "# Print the final generated question-answer pairs\n",
    "print(\"Generated Questions and Answers:\")\n",
    "for qa in qa_pairs:\n",
    "    print(f\"Question: {qa['question']}\")\n",
    "    print(f\"Answer: {qa['answer']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\mental_health.pdf', 'page': 15}, page_content='pleasant activities\\n If  a task seems too difficult, try breaking it  \\n into a series of  small steps\\n Above all reward yourself  for your efforts\\n Avoid discussions of  bad feelings. Solving  \\n problems is more helpful'),\n",
       " Document(metadata={'source': 'data\\\\Stroke disease pdf.pdf', 'page': 11}, page_content='The most common tests that happen when a healthcare provider suspects a stroke include: \\n• Computerized tomography (CT) scan. \\n• Lab blood tests (looking for signs of infections or heart damage, checking clotting ability and'),\n",
       " Document(metadata={'source': 'data\\\\mental_health.pdf', 'page': 15}, page_content='14\\n Coping with depression\\n Avoid sitting or lying about doing nothing\\n Identify things you used to do regularly and \\n  things which you used to enjoy\\n Plan to gradually increase the routine of   \\n pleasant activities'),\n",
       " Document(metadata={'source': 'data\\\\Stroke disease pdf.pdf', 'page': 3}, page_content='help prevent a TIA or stroke in the future. Healthy lifestyle changes and medicines often are used \\nto treat high blood pressure. \\n• Lower the amount of cholesterol and saturated fat in your diet. Eating less cholesterol and fat,'),\n",
       " Document(metadata={'source': 'data\\\\Malaria disease.pdf', 'page': 12}, page_content='re-establishment of transmission are required. \\nIn 2022, 34 countries reported fewer than 1000 indigenous cases of the disease, up from just 13'),\n",
       " Document(metadata={'source': 'data\\\\mental_health.pdf', 'page': 46}, page_content='45\\nNational Organisations\\nRethink Mental Illness ...................................0300 5000 927\\nInformation, advice and support for people affected by serious mental  \\nhealth problems'),\n",
       " Document(metadata={'source': 'data\\\\Stroke disease pdf.pdf', 'page': 10}, page_content='diagnostic imaging and other tests. During a neurological examination, a provider will have you do'),\n",
       " Document(metadata={'source': 'data\\\\Malaria disease.pdf', 'page': 9}, page_content='• abnormal bleeding. \\nPeople with severe symptoms should get emergency care right away. Getting treatment early for mild \\nmalaria can stop the infection from becoming severe.'),\n",
       " Document(metadata={'source': 'data\\\\mental_health.pdf', 'page': 38}, page_content='37\\nIf  someone close to you is experiencing  \\nemotional problems, encourage them to talk \\nabout their feelings and, if  necessary, get advice \\nfrom their GP . They may need a lot of  support \\nand their behaviour can be out of  character'),\n",
       " Document(metadata={'source': 'data\\\\diabetes 2.pdf', 'page': 16}, page_content='experience the symptoms of full diabetes. \\nThe risk factors for prediabetes and type 2 diabetes are similar. They include: \\n• obesity or overweight \\n• a family history of diabetes \\n• HDL cholesterol lower than 40–50 mg/dL')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.sample(text_chunk , k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rohit\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:20<00:00,  4.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# Initialize the Hugging Face model for text-to-text generation (consider using a better model if available)\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# Define the prompt template for generating questions based on context and answer\n",
    "QUESTION_PROMPT_TEMPLATE = (\n",
    "    \"Based on the following context and answer, generate a clear and meaningful question:\\n\\n\"\n",
    "    \"Context: {content}\\n\"\n",
    "    \"Answer: {answer}\\n\\n\"\n",
    "    \"Question:\"\n",
    ")\n",
    "\n",
    "# Define the prompt template for generating answers based on context and question\n",
    "ANSWER_PROMPT_TEMPLATE = (\n",
    "    \"Using the following context, provide a concise, informative, and understandable answer to the question:\\n\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Context: {content}\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "# List to store the generated question-answer pairs\n",
    "qa_pairs = []\n",
    "\n",
    "# Iterate through the documents and generate questions and answers\n",
    "for doc in tqdm(random.sample(text_chunk , k=200)):\n",
    "    content = doc.page_content\n",
    "\n",
    "    # Extracting a meaningful answer from content\n",
    "    if \"is\" in content:\n",
    "        answer = content.split(\"is\")[-1].strip().rstrip(\".\")\n",
    "    else:\n",
    "        answer = \"Unknown\"\n",
    "\n",
    "    # Create prompt for generating a question based on the context and answer\n",
    "    question_prompt = QUESTION_PROMPT_TEMPLATE.format(content=content, answer=answer)\n",
    "    \n",
    "    # Generate question using the Hugging Face model (Flan-T5)\n",
    "    question_response = qa_pipeline(question_prompt, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "    \n",
    "    # Clean up response to ensure it is a valid question\n",
    "    question = question_response.strip()\n",
    "    \n",
    "    # Create prompt for generating an answer based on the context and generated question\n",
    "    answer_prompt = ANSWER_PROMPT_TEMPLATE.format(question=question, content=content)\n",
    "    \n",
    "    # Generate answer using the Hugging Face model (Flan-T5)\n",
    "    # Set max_length to allow longer answers and min_length to enforce minimum length\n",
    "    answer_response = qa_pipeline(answer_prompt, max_length=50, min_length=10, num_return_sequences=1)[0]['generated_text']\n",
    "    \n",
    "    # Clean up response to ensure it is a valid answer\n",
    "    generated_answer = answer_response.strip()\n",
    "\n",
    "    # Append the results to qa_pairs\n",
    "    qa_pairs.append({\"context\":content,\"question\": question, \"answer\": generated_answer  })\n",
    "\n",
    "len(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fine_tunning_data= pd.DataFrame(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tunning_data.to_json(\"fineTuneData.json\") # saving data for fine tune in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well as its association with subsequent suicid...</td>\n",
       "      <td>What is the main idea of the passage?</td>\n",
       "      <td>monitoring of population rates of inten- tiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duals. Journal of the American Geriatric Socie...</td>\n",
       "      <td>What is the meaning of symptom-check-list scor...</td>\n",
       "      <td>testing of multiple hypotheses. Social Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health, 86(5):674–677.\\nSyme SL (2003). Psycho...</td>\n",
       "      <td>What is the population of the study that Syme ...</td>\n",
       "      <td>86(5):674–677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>should be screened for G-6-PD deficiency befor...</td>\n",
       "      <td>What is the best time to give primaquine?</td>\n",
       "      <td>During pregnancy : Women who are pregnant should</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of this publication to duplicate and  distribu...</td>\n",
       "      <td>What is the purpose of the passage?</td>\n",
       "      <td>to duplicate and distribute as many copies as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5)  Does the entire chain of command understan...</td>\n",
       "      <td>What is the most likely outcome of the counter...</td>\n",
       "      <td>enforcing the countermeasures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>the spleen \\n•  Decline in hemoglobin, hematoc...</td>\n",
       "      <td>If a large number of red blood cells are destr...</td>\n",
       "      <td>hemoglobinuria and symptoms if hemolysis severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>those patients with low-grade infections of lo...</td>\n",
       "      <td>What is the most common cause of malaria trans...</td>\n",
       "      <td>malariae infection may produce a unique immune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Estimation and interpretation of blood glucose...</td>\n",
       "      <td>What is the only test for diagnosis of diabetes?</td>\n",
       "      <td>Estimation and interpretation of blood glucose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>enzyme linked immunosorbent assay (ELISA ), wi...</td>\n",
       "      <td>What is the clinical significance of the method?</td>\n",
       "      <td>detect P. falciparum infections at parasite bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    well as its association with subsequent suicid...   \n",
       "1    duals. Journal of the American Geriatric Socie...   \n",
       "2    Health, 86(5):674–677.\\nSyme SL (2003). Psycho...   \n",
       "3    should be screened for G-6-PD deficiency befor...   \n",
       "4    of this publication to duplicate and  distribu...   \n",
       "..                                                 ...   \n",
       "195  5)  Does the entire chain of command understan...   \n",
       "196  the spleen \\n•  Decline in hemoglobin, hematoc...   \n",
       "197  those patients with low-grade infections of lo...   \n",
       "198  Estimation and interpretation of blood glucose...   \n",
       "199  enzyme linked immunosorbent assay (ELISA ), wi...   \n",
       "\n",
       "                                              question  \\\n",
       "0                What is the main idea of the passage?   \n",
       "1    What is the meaning of symptom-check-list scor...   \n",
       "2    What is the population of the study that Syme ...   \n",
       "3            What is the best time to give primaquine?   \n",
       "4                  What is the purpose of the passage?   \n",
       "..                                                 ...   \n",
       "195  What is the most likely outcome of the counter...   \n",
       "196  If a large number of red blood cells are destr...   \n",
       "197  What is the most common cause of malaria trans...   \n",
       "198   What is the only test for diagnosis of diabetes?   \n",
       "199   What is the clinical significance of the method?   \n",
       "\n",
       "                                                answer  \n",
       "0    monitoring of population rates of inten- tiona...  \n",
       "1    testing of multiple hypotheses. Social Science...  \n",
       "2                                        86(5):674–677  \n",
       "3     During pregnancy : Women who are pregnant should  \n",
       "4    to duplicate and distribute as many copies as ...  \n",
       "..                                                 ...  \n",
       "195                      enforcing the countermeasures  \n",
       "196    hemoglobinuria and symptoms if hemolysis severe  \n",
       "197  malariae infection may produce a unique immune...  \n",
       "198  Estimation and interpretation of blood glucose...  \n",
       "199  detect P. falciparum infections at parasite bl...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data in json format \n",
    "pd.read_json('fineTuneData.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rohit\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Load your dataset\n",
    "data_path = \"fineTuneData.json\"  # Path to your JSON file\n",
    "dataset = Dataset.from_json(data_path)\n",
    "\n",
    "# Tokenizer and Model\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Ensure the inputs are strings\n",
    "    inputs = [f\"Question: {str(question)}\" for question in examples['question']]\n",
    "    targets = [str(answer) for answer in examples['answer']]\n",
    "    \n",
    "    # Tokenize the inputs and targets\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\").input_ids\n",
    "    \n",
    "    # Add labels to the model inputs\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "processed_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Duplicate samples\n",
    "duplicated_data = processed_dataset.to_pandas().sample(frac=10, replace=True)\n",
    "processed_dataset = Dataset.from_pandas(duplicated_data)\n",
    "\n",
    "# Perform train-test split\n",
    "train_test_split = processed_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_15356\\4194048252.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808fe46b7fa949feb5dc9481266a46c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./flan-t5-finetuned-new\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=5e-5,  # Lower learning rate\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Enable mixed precision for better performance\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Fine-Tune Model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model locally\n",
    "model.save_pretrained(\"./flan-t5-finetuned-new\")\n",
    "tokenizer.save_pretrained(\"./flan-t5-finetuned-new\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
